{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5bb0ba-a0c3-42d9-b805-fc9cbb10b771",
   "metadata": {},
   "source": [
    "# Initial Imports and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6f43e-94f3-4737-82cb-f44b87e7ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports \n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO, RTDETR\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53ab908-37b3-40b4-8fc9-08428cd8d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video(model,video_source, save_path,video_prefix, n_frames=900): \n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    n_frame = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "    \n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.predict(frame)\n",
    "    \n",
    "            r = results[0]\n",
    "            im_bgr = r.plot()  # BGR-order numpy array\n",
    "            im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "    \n",
    "            #method 1\n",
    "            width, height = im_rgb.size\n",
    "            ratio =4\n",
    "            newsize =(width//ratio, height//ratio)\n",
    "    \n",
    "            f_n_frame = '0'*(5-len(str(n_frame)))+str(n_frame)\n",
    "    \n",
    "            im_rgb = im_rgb.resize(newsize, Image.LANCZOS)\n",
    "    \n",
    "    \n",
    "            # Visualize the results on the frame\n",
    "            im_rgb.save(f'{save_path}/{video_prefix}-frame-{f_n_frame}.jpg','JPEG',quality=85,optimize=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "        n_frame+=1\n",
    "        if(n_frame ==n_frames):\n",
    "            break\n",
    "    \n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9931577-b1ad-457c-97c8-35517bfa4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video_track(model,video_source, save_path,video_prefix, n_frames=900): \n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    n_frame = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "    \n",
    "    \n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame,persist = True)\n",
    "    \n",
    "            r = results[0]\n",
    "            im_bgr = r.plot()  # BGR-order numpy array\n",
    "            im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "    \n",
    "            #method 1\n",
    "            width, height = im_rgb.size\n",
    "            ratio =4\n",
    "            newsize =(width//ratio, height//ratio)\n",
    "    \n",
    "            f_n_frame = '0'*(5-len(str(n_frame)))+str(n_frame)\n",
    "    \n",
    "            im_rgb = im_rgb.resize(newsize, Image.LANCZOS)\n",
    "    \n",
    "    \n",
    "            # Visualize the results on the frame\n",
    "            im_rgb.save(f'{save_path}/{video_prefix}-frame-{f_n_frame}.jpg','JPEG',quality=85,optimize=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "        n_frame+=1\n",
    "        if(n_frame ==n_frames):\n",
    "            break\n",
    "    \n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c2a54-c6dc-44fa-9dc1-233f01969ca7",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ab7a6-a39a-4889-9967-53c9e88bb334",
   "metadata": {},
   "source": [
    "## Yolov8 nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b3a3c6-8093-4866-825d-a88d526fa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO('yolov8n.pt') \n",
    "results = model.train(data='dataset.yaml', epochs=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3747a0-660e-42d9-bf00-009efc6faa99",
   "metadata": {},
   "source": [
    "## Yolov8 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e344d-aa84-44a8-b96a-743d2769dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO('yolov8s.pt')  \n",
    "results = model.train(data='dataset.yaml', epochs=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1740c6d-485d-4127-9c17-9b6637aa65cd",
   "metadata": {},
   "source": [
    "## Yolov8 medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d4bb2-98c1-4fb0-a655-8104c27b5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO('yolov8m.pt')  \n",
    "results = model.train(data='dataset.yaml', epochs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfa821-53bc-4e64-84ca-83f0fe5918c9",
   "metadata": {},
   "source": [
    "## RTDETR-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fd08e-4416-4a3b-bf13-70780e65f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "results = model.train(data='dataset.yaml', epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5e880-39d2-4276-9d3b-2956b18d3a5b",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c8824-7717-4f02-a7fe-9b9060056bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 'video_test/CE-176.mp4'\n",
    "\n",
    "model = YOLO('runs/detect/yolov8n_trained/weights/best.pt')\n",
    "save_path = 'results/detect/yolon'\n",
    "video_prefix  = 'CE-176'\n",
    "run_video(model,video_source, save_path,video_prefix, n_frames=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e78f43-85e1-40e5-abd9-062f0c1247e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 'video_test/CE-176.mp4'\n",
    "\n",
    "model = YOLO('runs/detect/yolov8s_trained/weights/best.pt')\n",
    "save_path = 'results/detect/yolos'\n",
    "video_prefix  = 'CE-176'\n",
    "run_video(model,video_source, save_path,video_prefix, n_frames=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bf129-7c61-429f-94ea-42bcc4db1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 'video_test/CE-176.mp4'\n",
    "\n",
    "model = YOLO('runs/detect/yolov8m_trained/weights/best.pt')\n",
    "save_path = 'results/detect/yolom'\n",
    "video_prefix  = 'CE-176'\n",
    "run_video(model,video_source, save_path,video_prefix, n_frames=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a4619-35e2-4f4e-8680-673639359168",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 'video_test/CE-176.mp4'\n",
    "\n",
    "model = RTDETR('runs/detect/rtdetr-l_trained/weights/best.pt')\n",
    "save_path = 'results/detect/rtdetr-l'\n",
    "video_prefix  = 'CE-176'\n",
    "run_video(model,video_source, save_path,video_prefix, n_frames=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed723a78-f2b7-4980-ba2e-3ab316ad1a24",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454079a4-0154-418e-82c1-fb01de93f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 'video_test/CE-176.mp4'\n",
    "video_prefix  = 'CE-176'\n",
    "\n",
    "model = YOLO('runs/detect/yolov8n_trained/weights/best.pt')\n",
    "save_path = 'results/track/yolon'\n",
    "run_video_track(model,video_source, save_path,video_prefix, n_frames=900)\n",
    "\n",
    "model = YOLO('runs/detect/yolov8s_trained/weights/best.pt')\n",
    "save_path = 'results/track/yolos'\n",
    "run_video_track(model,video_source, save_path,video_prefix, n_frames=900)\n",
    "\n",
    "model = YOLO('runs/detect/yolov8m_trained/weights/best.pt')\n",
    "save_path = 'results/track/yolom'\n",
    "run_video_track(model,video_source, save_path,video_prefix, n_frames=900)\n",
    "\n",
    "model = RTDETR('runs/detect/rtdetr-l_trained/weights/best.pt')\n",
    "save_path = 'results/track/rtdetr-l'\n",
    "run_video_track(model,video_source, save_path,video_prefix, n_frames=900)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2cfa6-3201-4958-925a-7cce2f4b5e16",
   "metadata": {},
   "source": [
    "# Create Comparison Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ab62277-7642-4178-a536-d208008606cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [13:03<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import libraries \n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "\n",
    "task = 'track' \n",
    "for i in tqdm(range(900)):\n",
    "    \n",
    "    # create figure \n",
    "    fig = plt.figure(figsize=(20, 14)) \n",
    "    \n",
    "    # setting values to rows and column variables \n",
    "    rows = 2\n",
    "    columns = 2\n",
    "    n_frame = i\n",
    "    f_n_frame = '0'*(5-len(str(n_frame)))+str(n_frame)\n",
    "    image_name = f'CE-176-frame-{f_n_frame}.jpg'\n",
    "    \n",
    "    \n",
    "    # reading images \n",
    "    Image1 = cv2.imread(f'results/{task}/yolon/{image_name}') \n",
    "    Image1 = cv2.cvtColor(Image1, cv2.COLOR_BGR2RGB)\n",
    "    Image2 = cv2.imread(f'results/{task}/yolos/{image_name}')  \n",
    "    Image2 = cv2.cvtColor(Image2, cv2.COLOR_BGR2RGB)\n",
    "    Image3 = cv2.imread(f'results/{task}/yolom/{image_name}') \n",
    "    Image3 = cv2.cvtColor(Image3, cv2.COLOR_BGR2RGB)\n",
    "    Image4 = cv2.imread(f'results/{task}/rtdetr-l/{image_name}') \n",
    "    Image4 = cv2.cvtColor(Image4, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Adds a subplot at the 1st position \n",
    "    fig.add_subplot(rows, columns, 1) \n",
    "    plt.rcParams['font.size'] = 24\n",
    "    # showing image \n",
    "    plt.imshow(Image1) \n",
    "    plt.axis('off') \n",
    "    plt.title(\"yolov8-n\") \n",
    "    \n",
    "    # Adds a subplot at the 2nd position \n",
    "    fig.add_subplot(rows, columns, 2) \n",
    "    \n",
    "    # showing image \n",
    "    plt.imshow(Image2) \n",
    "    plt.axis('off') \n",
    "    plt.title(\"yolov8-s\") \n",
    "    \n",
    "    # Adds a subplot at the 3rd position \n",
    "    fig.add_subplot(rows, columns, 3) \n",
    "    \n",
    "    # showing image \n",
    "    plt.imshow(Image3) \n",
    "    plt.axis('off') \n",
    "    plt.title(\"yolov8-m\") \n",
    "    \n",
    "    # Adds a subplot at the 4th position \n",
    "    fig.add_subplot(rows, columns, 4) \n",
    "    \n",
    "    # showing image \n",
    "    plt.imshow(Image4) \n",
    "    plt.axis('off') \n",
    "    plt.title(\"rtdetr-l\") \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'results/{task}/combined/{image_name}', bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12b52206-f4bb-4e34-8270-a29760af0e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './results/track/combined/*.jpg':\n",
      "  Duration: 00:00:30.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1948x1247 [SAR 100:100 DAR 1948:1247], 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x56304a114400] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mprofile High, level 5.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/track/combined.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 1948x1246 [SAR 1:1 DAR 974:623], q=2-31, 30 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  900 fps= 18 q=-1.0 Lsize=  100524kB time=00:00:29.90 bitrate=27541.5kbits/s speed= 0.6x    \n",
      "video:100512kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.012247%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mframe I:5     Avg QP:24.14  size:224015\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mframe P:229   Avg QP:26.47  size:150065\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mframe B:666   Avg QP:27.97  size:101259\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mconsecutive B-frames:  1.2%  0.2%  0.3% 98.2%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mmb I  I16..4:  8.7% 86.8%  4.5%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mmb P  I16..4:  2.0% 37.6%  0.6%  P16..4: 23.4%  9.1%  4.8%  0.0%  0.0%    skip:22.4%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mmb B  I16..4:  0.3% 10.1%  0.4%  B16..8: 35.0% 12.7%  4.8%  direct: 3.2%  skip:33.4%  L0:37.8% L1:36.3% BI:25.9%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0m8x8 transform intra:93.3% inter:87.3%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mcoded y,uvDC,uvAC intra: 91.2% 58.2% 10.5% inter: 30.1% 16.8% 0.5%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mi16 v,h,dc,p: 37% 52%  1% 10%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  7% 16% 37%  6%  6%  4%  7%  5% 12%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 20% 16%  7%  7%  6%  8%  6% 10%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mi8c dc,h,v,p: 62% 23% 12%  3%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mWeighted P-Frames: Y:6.1% UV:3.5%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mref P L0: 48.6% 16.1% 25.7%  9.3%  0.3%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mref B L0: 86.6% 10.3%  3.1%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mref B L1: 94.3%  5.7%\n",
      "\u001b[1;36m[libx264 @ 0x56304a05d1c0] \u001b[0mkb/s:27446.24\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -framerate 30 -pattern_type glob -i './results/track/combined/*.jpg' \\\n",
    "  -c:v libx264 -pix_fmt yuv420p -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" results/track/combined.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c965d14-0784-4c7f-91de-75d85ffca3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"results/detect/combined.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"results/detect/combined.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_recognition",
   "language": "python",
   "name": "sign_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
